{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3635a131",
   "metadata": {},
   "source": [
    "## Tutorial: Fine-Tuning Whisper for French Telephone Conversations\n",
    "\n",
    "Automatic Speech Recognition (ASR) systems like OpenAI’s Whisper deliver impressive out-of-the-box performance by leveraging an enormous, multilingual corpus. However, when your use case involves specialized vocabulary or languages that were underrepresented during pretraining, fine-tuning can make a significant difference. In particular, if your data diverges substantially from Whisper’s original training set—whether in domain, audio characteristics, or speaker demographics—adapting the model to your specific dataset often yields notable gains.\n",
    "\n",
    "Below is the list of languages for which Whisper achieves a word error rate (WER) below 50%, an industry-standard threshold for speech-to-text accuracy:\n",
    "\n",
    "Afrikaans, Arabic, Armenian, Azerbaijani, Belarusian, Bosnian, Bulgarian, Catalan, Chinese, Croatian, Czech, Danish, Dutch, English, Estonian, Finnish, French, Galician, German, Greek, Hebrew, Hindi, Hungarian, Icelandic, Indonesian, Italian, Japanese, Kannada, Kazakh, Korean, Latvian, Lithuanian, Macedonian, Malay, Marathi, Māori, Nepali, Norwegian, Persian, Polish, Portuguese, Romanian, Russian, Serbian, Slovak, Slovenian, Spanish, Swahili, Swedish, Tagalog, Tamil, Thai, Turkish, Ukrainian, Urdu, Vietnamese, and Welsh.\n",
    "\n",
    "Although Whisper was pretrained on 98 languages in total, the list those where WER falls below 50%. For any languages not shown above, Whisper will still attempt transcription—but accuracy is expected to be substantially lower.\n",
    "\n",
    "In this tutorial, we’ll walk through fine-tuning the Whisper **small** model specifically for French telephone conversations, using a dataset preprocessed by Diabolocom (Maheshwari et al., 2024). We chose the small variant of Whisper to keep the demonstration concise, but the same principles apply to larger or smaller model sizes. To make the process GPU-efficient and reduce the number of trainable parameters, we’ll employ Low-Rank Adaptation (LoRA) (Hu et al., 2021), which allows us to adapt Whisper even with limited hardware resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a48e57d",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies\n",
    "\n",
    "First, install all the Python libraries we’ll need for audio processing, dataset handling, training, evaluation, and a demo UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6250ade5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.diabolocom.ai\n",
      "Requirement already satisfied: transformers in /root/miniconda3/envs/canary/lib/python3.10/site-packages (4.48.3)\n",
      "Requirement already satisfied: peft in /root/miniconda3/envs/canary/lib/python3.10/site-packages (0.15.1)\n",
      "Requirement already satisfied: torchaudio in /root/miniconda3/envs/canary/lib/python3.10/site-packages (2.6.0)\n",
      "Requirement already satisfied: datasets in /root/miniconda3/envs/canary/lib/python3.10/site-packages (3.5.0)\n",
      "Requirement already satisfied: accelerate in /root/miniconda3/envs/canary/lib/python3.10/site-packages (1.6.0)\n",
      "Requirement already satisfied: gradio in /root/miniconda3/envs/canary/lib/python3.10/site-packages (5.25.2)\n",
      "Requirement already satisfied: jiwer in /root/miniconda3/envs/canary/lib/python3.10/site-packages (3.1.0)\n",
      "Requirement already satisfied: evaluate in /root/miniconda3/envs/canary/lib/python3.10/site-packages (0.4.3)\n",
      "Requirement already satisfied: torchinfo in /root/miniconda3/envs/canary/lib/python3.10/site-packages (1.8.0)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from peft) (7.0.0)\n",
      "Requirement already satisfied: torch>=1.13.0 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from peft) (2.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from torch>=1.13.0->peft) (4.13.2)\n",
      "Requirement already satisfied: networkx in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from torch>=1.13.0->peft) (2024.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from torch>=1.13.0->peft) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from torch>=1.13.0->peft) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from torch>=1.13.0->peft) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from datasets) (3.11.16)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from gradio) (24.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from gradio) (4.9.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from gradio) (0.115.12)\n",
      "Requirement already satisfied: ffmpy in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from gradio) (0.5.0)\n",
      "Requirement already satisfied: gradio-client==1.8.0 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from gradio) (1.8.0)\n",
      "Requirement already satisfied: groovy~=0.1 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from gradio) (0.1.2)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from gradio) (3.0.2)\n",
      "Requirement already satisfied: orjson~=3.0 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from gradio) (3.10.16)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from gradio) (11.1.0)\n",
      "Requirement already satisfied: pydantic<2.12,>=2.0 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from gradio) (2.11.3)\n",
      "Requirement already satisfied: pydub in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: ruff>=0.9.3 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from gradio) (0.11.5)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from gradio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from gradio) (0.46.2)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from gradio) (0.13.2)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from gradio) (0.15.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from gradio) (0.34.1)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from gradio-client==1.8.0->gradio) (15.0.1)\n",
      "Requirement already satisfied: click>=8.1.8 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from jiwer) (8.1.8)\n",
      "Requirement already satisfied: rapidfuzz>=3.9.7 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from jiwer) (3.13.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from aiohttp->datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from aiohttp->datasets) (1.19.0)\n",
      "Requirement already satisfied: certifi in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from pandas->datasets) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (14.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /root/miniconda3/envs/canary/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers peft torchaudio datasets accelerate gradio jiwer evaluate torchinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e932fd",
   "metadata": {},
   "source": [
    "## 2. Setup & Authentication\n",
    "\n",
    "Set your model identifiers and language parameters. Then authenticate with Hugging Face so you can download models and optionally push your adapter checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a673b09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"openai/whisper-small\"\n",
    "language = \"French\"\n",
    "language_abbr = \"fr\"\n",
    "task = \"transcribe\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304a3f02",
   "metadata": {},
   "source": [
    "Your Hugging Face token can be found in [Hugging Face Hub.](https://huggingface.co/settings/tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5730cdf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9652f6588e0e47bebc1aa97adcc54e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bada0b",
   "metadata": {},
   "source": [
    "## 3. Data Loading\n",
    "\n",
    "We load a French telephone speech-to-text dataset processed by Diabolocom from Hugging Face Hub https://huggingface.co/datasets/diabolocom/talkbank_4_stt.\n",
    "\n",
    "The dataset is structured into segment and switch parts, we are interested here into the segments and the \"train\" and \"test\" splits.\n",
    "\n",
    "For this demo, we select only 1 000 samples from each split and ensure that audio is resampled to 16 kHz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8aaed86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict, Audio\n",
    "\n",
    "talkbank_fr = load_dataset(\n",
    "    \"diabolocom/talkbank_4_stt\", \n",
    "    data_dir=\"fr/segment\", \n",
    "    verification_mode=\"no_checks\")\n",
    "\n",
    "talkbank = DatasetDict({\n",
    "    \"train\": talkbank_fr[\"train\"].select(range(1000)), \n",
    "    \"test\": talkbank_fr[\"test\"].select(range(1000))\n",
    "})\n",
    "\n",
    "talkbank = talkbank.cast_column(\"audio\", Audio(sampling_rate=16000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8cba79",
   "metadata": {},
   "source": [
    "## 4. Explore the dataset\n",
    "\n",
    "Let’s listen to a sample, inspect its duration and metadata, and plot the distribution of audio lengths in train vs. test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d7a9c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_seconds(seconds_input):\n",
    "    \"\"\"\n",
    "    Turn a number of seconds (possibly fractional) into a compact string,\n",
    "    omitting zero-value day/hour/minute units, and always showing seconds (with\n",
    "    up to millisecond precision, dropping trailing zeros).\n",
    "    \"\"\"\n",
    "    remaining = float(seconds_input)\n",
    "    parts = []\n",
    "    for label, unit_secs in ((\"d\", 86400), (\"h\", 3600), (\"m\", 60)):\n",
    "        qty, remaining = divmod(remaining, unit_secs)\n",
    "        if qty >= 1:\n",
    "            parts.append(f\"{int(qty)}{label}\")\n",
    "    parts.append(f\"{remaining:.3f}s\")\n",
    "    \n",
    "    return \" \".join(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "144efe8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"data:audio/wav;base64,UklGRiQ8AABXQVZFZm10IBAAAAABAAEAgD4AAAB9AAACABAAZGF0YQA8AACT/Gv8Kvz9+sf6I/qj+ZT4VvhQ+OX49fkJ+/b7QPx7/Mn8Vf1t/Yj9EP5Z/+MA9wFXAgQCiwEJAQQBRQHDAR8CKQLrAXgBCAGDANH/kf5N/Yz8efx8/DL8sftH+wH7RvpJ+Wf4Hfgm+DD4J/gs+En4GfjB93v3svc6+Nb4Vfm++TD6jPra+hz7aPu++yb8aPy1/Dv9+/31/iEAewG0AoADlQNJAz4D8AMoBVMG+gb3BqEGMga6BS4F5AT2BC0FQwUZBbsEOQSqAwsDkwJCAu0BPQFBAE//tv6S/qj+r/5B/nr9oPwb/BP8XPya/Kb8p/y5/Pv8I/0F/bX8oPz9/LH9X/6Y/mL+/P3E/dz9Uv7w/nH/l/9f/yj/SP/P/1YAiABUABcAGABdAK4A4gATAUYBcwGOAb0B8QEFAusB7QFMAucCSwMsA9MCqALVAvgC1wJ/AjECBALkAcYBnAFwAS8B6ACwAKQAuwDPAMYAsAC6AOEADQEEAccAiwCTANkAJAFHAUABQAFRAV8BSgEhAfAAuQCFAHcAnwDKAMwAngB8AIsAxADvAAYBLAFmAZkBtQHUAQQCSAJ9ApIClgKvAt4CAAMOAxkDLAMpAwQDxQKbApwCqgKkApACiwKLAnkCTwI1AkUCcQKAAmACQAJPAooCswK3Aq4CxALyAgkD7QKzAocCfgKIAo4ClQKfAqYCjwJlAjkCDwLhAa8BnwG+AfgBHAIXAvcBzwGrAZoBpgG8AccBuwGuAbYB4gENAhYCBALtAdkBvwGxAcAB9wFCAnYCcAI+AgwC+gESAkcCgwKqArQCmAJjAjUCJgI2Ak8CbAKKAq0CzwLiAuECzgK3AqECmgKyAtsC/gITAxAD7gKqAmUCQgJLAm4CjAKYApQCiAJvAlQCTQJkAnkCbQJLAiwCIgIYAvwBxQGUAYIBhwGDAWIBLwH+AOsA+AAfAUoBZQFkAVUBUwFlAXoBfQF7AYoBuwHzAQsCAQLuAeYB2QHGAbUBswG7AboBoAFyAUkBKgEJAeoA0wDKAMcAsgCWAJEAtADrABYBKwFDAXkBwwH5AQMC/QEOAkUChwKlAokCQgL/Ac8BtAGVAWIBHgHZAJcAVQAcAPL/zf+g/3T/Yv98/6v/x//A/67/q/+u/7X/wv/l/yAAZQCTAJcAgQBlAFEASgBTAGMAaABdAEAAIwANAPz/7f/Z/8f/tf+X/3D/T/9P/2z/if+Q/4r/jf+W/53/nP+m/8D/2P/Y/73/nf+O/5b/qf/A/9X/6v/4//T/1v+i/2//WP9n/4D/if97/2j/Wv9B/xH/0v6n/p7+qv6z/rL+p/6R/m7+R/4x/jH+NP4e/vr96f0G/kT+ff6e/p3+hf5r/lb+Uv5k/nr+gv5v/kr+Hv7z/dT9yv3T/dT9vf2P/Wf9Xf15/ar90v3p/fb9Dv40/l7+eP6A/oD+gf6F/o3+mv6h/p7+hv5i/jv+GP70/cz9pv2O/Y/9pf26/bv9qv2W/Yv9jP2N/Yb9ef18/Zn9wv3h/eX9z/2s/Zr9nP2v/cn91P3N/bz9pP2N/Xf9Zf1Y/Vr9bf2B/YH9Zf04/Q39/vwJ/Rz9Jf0o/TP9Sf1f/WD9T/09/T39Tf1k/X/9mf2i/Yv9Xf08/Ur9eP2c/Zz9j/2Y/bz93v3i/db90v3b/dj9uf2Q/X/9kP2m/aP9hf1k/VD9P/0m/Q39CP0V/R/9Ff37/Ob85vwA/TP9dP2p/bv9rf2j/br94f3o/cH9kP2K/a/91v3Z/cL9tP2//dT93/3k/ev99P35/f/9D/4k/ir+F/75/ez9+/0U/ir+PP5S/mX+af5Y/jn+Gv4K/hb+QP5x/oH+Xv4h/vj98P3y/ej95P0D/jf+TP4i/t39xf3u/Sv+SP5I/lX+gf60/s3+1/73/jj/ev+X/4f/a/9h/2v/ef97/3X/c/91/3L/Y/9T/1L/YP9e/zX/9v7P/t7+Cv8i/xD/7/7j/vT+EP8p/0H/VP9c/1z/Zf+C/6P/s/+2/8v/9v8VAA0A9P/7/y4AXgBaADAAFQAdACcADADX/6j/jP9w/07/Qf9e/5H/tP+7/8H/3f8DABoAIAApAEEAYAB5AJEAqgC3AK0AlQCFAIYAhQB1AGEAWQBVAD8AGAABAA4AJwAfAO//vv+2/9H/6f/u//D/AwAfACgAFwD///j/AAAHAAYAAAD7//L/3f+8/5n/ff9o/1L/Of8p/zj/a/+v/9//7f/p/+3//v8JAAUAAAAOAC4ASQBOAEIANQAnABYADAAiAF8ApgDOAMIAjQBEAPz/x/+9/+L/DwAXAPH/wv+7/9z//P/5/9v/vv+r/53/lv+r/+r/NABaAEkAJwAxAHkA0gD7AN4AmwBgADgADADW/7P/wf/1/xsAEQDn/8f/xf/S/+P/AAAuAFkAVQAgAOz/9/9LALUA7QDSAHgAGADr/wQATwCTAJwAXgDz/4f/Of8Z/yj/Yf+y/wEAMgAwAAEAyf+3/+n/RQCPAJ4AhgB8AJ0AzwDfALkAdwBDADYASwBlAGcARwAWAOz/yP+V/0//HP8q/2n/if9N/9b+jP6q/gb/T/9y/5r/7f9RAJYApgCUAHIATgBIAIMA7wA7ARgBlwAiAAkAOQBbAEQAEwD2/+f/xv+U/3r/l//Q/+v/yP+C/1X/bv/L/0EAmQCyAJEAUwALAMD/eP9J/0r/cv+d/6z/nf+D/3L/dv+U/7z/0f+//5r/k/++//n/DgD5/+D/6v8QAD4AdwDKACIBSgEmAd8AuQDOAPgACgH7ANkArgB1ACwA1v94/yD/8P4B/zz/X/9D/wb/7f4P/z//Uf9T/3H/vP8XAG8AxwAeAVYBUAEeAfIA5wDeALUAbAAhAOP/rf+B/3H/e/99/1f/Df/A/oj+dv6f/hP/q/8SABYA4//b/ygAmwDtAA8BFgEEAcUAaQAzAFUAtQAKASIB/QCrAEAA7P/i/yIAXwBOAP7/wf/A/8n/oP9R/x3/E/8F/9n+tP7E/vT+CP/l/qz+dP4y/ub9zP0q/vr+5P+KAMAAiQASALr/7f+/ALEBFgK8ARkBuQDCABIBnAFfAggDEQNeAocBNgFxAaoBkAFQAQgBZwA8/0b+0P5OAZ8E1AazBkwEtQC2/XX9XgFrCNIObBAbDNkEV/9h/lkBTAUPB9QECv9p+Lj0bPbk/OQElAqrCh4CQe53zwKtdJWimBO94/eELmxE6S3m+ifPn8pU8jks+VHoS8gfQ+rXylDRuPYTI5c7UjKyDnnoSNd+4s79RhS7F4gIZfJF4zLjbfDxABgJBQSZ93Pvs/Ll/eAGdAY3/uv1aPQM+x0GpA9CEs8Le/8o9Xj0cv66Cw0SoAzy/5n1bPTm+9IFcgtoCaQAd/Xf7bXuB/ijA60IuAIv9g/taO6c+K4DhQjABZj+9/aU8Urw7fPF+nEA7AAo/B72GPMu9G73ffoz/D38ifrT9/b1l/ZL+c77Zfyx+8j7xf2zAMQCBQPMAQMAnf5r/sn/CgLEA/gDEwNhAogC1wIZAvP/SP2F+7j7Hv4JAvgFAAjbBu0CWP7i+0z9FAKTB3AK1AjHA3r+4/ud/N3+SQDO/9j9j/sf+nj61PwBAJsB3v+v+3L4NPnB/aYCNAScAT39Uvpo+rz8P//8/yj+pfrO9wb4rPtIAFsCYwA5/Dj5PPlo+6X9p/5e/i79lvuJ+iX7Zf1//2j/Kf0P+zr7XP1g/wcAAABfAPUA9wC6AJgB1wOfBREF7gIJAsoDJwbwBasCOf94/i4AxgGAAfz/xf5p/pj+Vf/wANgCXANvAUj+hvyf/W8AhAJ2As0A+/4P/lz+xf/NAZMDOwSxA9UCrAJ1A5QEYgXKBRkGXAY0BlkFJARoA7sD4ATjBdEFVQTjAXH/B/5M/hMAPwJVA5ECmwAH//b+OgC2AX0CawLNAesAHwADAPoAZALOAlwB9f6L/Sr+7f8EAYoA+v5A/f37sPvs/JH/DAJAAqn/Vvw2+0z91QAjA/ICDwE///v+1wApBP4GGwflA3P/LP3g/ioDzwZ8B00FDgKg/wP/MAA3Aq0DsgO+AjACywLRA9kDdQKrAM//OwBqAcoCDASzBP0DtwHu/k/9vv2r/9gBZwP5A00DaAE2/0/+lf8GAoYD4gL2AJ7/0v8WAXQCbgPrA7oD1gLoAf4BWQPhBCwFFgTwAicD5AQtB/QIwwmVCZoIYAfMBmsHzwjsCUMKYAoGC/8LMgzoCqwIuga1BTkFkQSJA2kCawGMAM//RP+y/n79Rvua+Mr2vPYL+F75lPmd+Ef3ffa39tH3PPlT+s76/vqL+7f8A/6X/i/+lP0K/i8AWgMHBg4HdwZRBboE/gSZBeAFlQXpBCcEggMjAzEDkAPRA4EDoQK6AVcBfwHHAckBbAG6ALT/dP5o/Rv9sP2a/hb/3P5O/gD+Jv6H/t/+If9d/4H/a/8a/8X+mv6A/ib+V/1M/J/76vtM/Ub/CwENAkQC+wFdAVwAAv/H/ZT9P//3At8HMAweDhQNSwoMCAwIXwrZDVoRdRQOF8IYHhlHGAgX+BXbFDgTaBGGEAoRwhGkEJQMIAbH/gX4NvNa8Tny1vOb837wuutY51nkh+KE4Vbh6eG54m3jYuQp5nzoHeoR6tHoHuiE6R3tt/H69Un5sPtv/d7+hwDXAp8FKggKCoULIQ39DuMQtxJxFKQVrRWUFF4TCxNxE2sTNxJSENQOTg5rDogOQw5wDdoLfAnwBlEFNwXdBaYFrwO5AE3+IP2z/Dj8W/sh+pv4MvfM9uz3wfmr+uz5aPh/94P3qfc390n2afXv9Or0bfVy9nz3mfcX9mPzBfF88N7xyPPG9LX0g/TK9Bj1rfSP83byCfKI8iL09PaD+pf9E//u/hD+Tf3c/Nr85v3BADsF3wkTDXIO6g6QD60QCRK3ExMWDRnvGxMejB+6IGghsSD4HdEZ5RXZExoUdBXDFUYTmg21BUj9GvZ88Yzvyu7p7JzooeLn3NDYe9ZZ1dvUf9Tf0zvTwNOQ1lDb/N994pbiDOL94iLmverh7z71fvqJ/lIAawD7AJIDZQdsCucLBg0LD7MRBBTPFYMXuxg9GMwVLhOcElgUYxamFtgUPBIOEKMOvQ0bDXYMgwsxCtsIzQfPBnYF8gMIAw8DPQNnAkAAj/06+535ofj/91n3dfaf9Un1FfXd8z3xhO5U7YXteu1q7GLrfutN7LbstuwO7aHtdu167AbsL+1q74TxGfNH9Jf0fPPV8bLxDfSE9+H5e/pp+uP6Hfyg/eT+U/9+/hj9cP0GAv8KJhUiHOodPRypGmcbFB4JIVwjgSV3KJcs4zBlM2gyzy0vJ4UgDRtMF40VZRXwFGkRPAlQ/Urw/eRl3QPaa9nX2D/W8NGEzbHJ+8WMwgzB6cKsx9jN3tQL3a7lkuzx73/wBPEo9MP6vQP0DEwUbBj1GGYWDRLRDToLXwofCqUJLAnfCIQHeQMD/bf2TfN881j2zPry/4oEZQemCO8JvgwMEcIVMRqLHgAj7iY3KVYp1SevJWIj4iBLHv0bsBkXFjEQ2wgsAhj9mvjB82vvGe2j7DbsjOro5wXlZOIH4V3iQOb56b3q5+h452noxeqv7NTtGu/C8CTy2PIr8zfzdPJg8FftZup46Lnnrufd53zoRupn7crw5PIB843xtu/K76X1pgSZGzYzv0L/RnREYUJ7RLpJFFBMV0pfLWVIZNNaUUznPfswIyN0E2oF3/yp+Krzzup93+/THsgsvH+zUbKQuNLBj8rH0t3aseBH4t7hjOSa7Dv3VwDnBmkMXRH6E1gS3gz3Bej/XvsJ+OL1AfVD9CvxOeox4fHZ5dZw1wLaVN655E/sX/NW+fv+vQQDCowOTRM1Gd4fMya8K3wwATR/Ncg0dDJJL/ErFykLJzUlkyK3HsQZsxOaDMAFMwGt/7b/j/8d/xv/N/+Q/q39Xf46AaoE/AZnCNoJ1QrsCR4HOwSWAmsBUf9J/Hf5Bfdo8z3tXeWJ3vfabtrf2rfaPdqu2m7cit7T3+/fW9/d3mTf1uFH5mHrSu9d8Y7yFvQf9hj4pfl++vP5M/i5+LcBhRbzMS1IWVBSTMlFJEQiRzdLyU8yVklccVw/VOFHVjyeMCYgVQuc+YXxePF18gHwm+q64x7bNNEsyYfGscmu0DjaEOZl8if7I/0/+dbzX/G88+35JQFrBv4HwgWCACL5lPAk6BThHdyv2TfaWN3f4KDhJd5w2JjUtNUS3NDlkfC++roDaAuEEbIVFBiEGfEasxzVHoEhQCQKJTMhLRjnDLsDKP/M/u4A9AN/BqAHsgdbCMoKOA4REVQT4xblHMAjWygXKeImiiP3H0EcmhhYFU8S2A50CvgEWP4L96LwAu157DftQ+1e7D7ruekS5+7jPuKv4pXjWOOw4h3jH+Tc40vireFS48PlA+cg5yXnuual5CPh6N2229rZYtgv2aHdU+RG6qbtWu6k7O7oi+Wr50j1xxAoNW1WKGjEZs9allG8UdhXXl3fXx9gLV1OVEFFJDMXIAoLwvPD3hjSos56zyDQttDb0vnUpdMfz6PMQ9Eb3XTsBfw2ChMVxhlGFz0Q4ghrA1L/dPtw9xDzue0V527f/NaPzbPDkrvZt9O508DlyofVeN415Y7rnPMJ/YMF/AsiEswZLiLFKBAsFCzTKCkiYBknETQL5QbWAsn+4voJ9qHuP+WR3fXbNuKE7hH9eAoJFXscGyG5I/4lvik7L5A0nDf9N1A2+zFWKVUc3A2BAdT4e/MY8Zrx3/NO9YLzL+6G5/biDOO252DuVPTA+Pz7Vf0C+6D0iuzx5WLit+F049Hm0ukA6o7mMuGL3PTZCdmQ2KLXL9bE1NjTm9Op1C3YW94k5a3pWesB7MXsYOyA6t/rXfhuE702UlXCZCNkGlueUotOh02pTRdPbVHyUC9JDDqkJ60U9f856c3VxMzyzurVf9uF37/kwOrM7SzsDulV6SfvgPmbBv0UziEJKFojZxRRAeTwmuX+3ePY99a515PXJdN2y3fEDcAPvX67wr7fyf3ay+yC+9YGgQ8eFQ8XFhYsFGsTMBVuGTAegyB4HhQYcA7jAmX3k+5E6jHqquw+8Cf0jPdd+R/5X/eg9VP2R/y7CIMZ3SmyNcc74DzZOV8z8Cr5Io4dOxsEGykb0RliFfUMLgHX9PfrQuku7BLy2viz/10FqgfDBYoBc/3u+Zz29fQm9y38pf9h/lj58PK667rjEt2j2lbcQt824Rbiz+G839Tc4tvr3VPgQuBm3mzdP94J4O7ixudT7ZHwevAI74jtiepu5U3ixed9+dQVXDdDVtxpHW1RY1BWbk4BTQlPZVIwVtJXNlNaRscyIxuQAUvpktd/0BjTK9pF4a7nY+639Er45Pc+9a7z5PUu/a8JuBmQKJAvSCoQGhUFvPEz48DZn9Sh0u7R09ALz4XNpsx3yxXJqcaAx+fOi92A8P0CfRFVGz8hFiMyIO8ZHxTsEeQSDhRHE1wQawsTBOT6LvJE7H/p5+hE6ovuL/bm/y0JwQ+QEiYSghBGEKUTkhshJyozTDupPPI3HjA/J5AdqRPXCyII2AdgCP8HkgYXBCoAOvvZ9lH0+vNt9tf80AbvENIWlRZZEU8JpwDw+TX3/vd8+Z/5z/jU93n1/O8u6E/hl91X3Nrbvduh3Jne/OB64zjm7eip6sDqf+m95/jlXuSm41rlcOpn8YL2yfZx8qrrD+R83YXdjezmDUA5wl7ncm51dW3MYVZWxk0BSnJKD0yhSwlHyTwrLIIW//656NPVecjwws7FTM8y3d3tTP44CegKpgU8AMn/swQ5DdQX+CEqJygkGxq0DLj9kez12WjJVb5duVi5cr2+xLbMNNI81ODUPtcf3YLmfvIKACAOYxvaJUwreSohJI0aLBCyBkj/sPrY+Hb4tPdo9cHxz+2O6oLoZujF6//zRwBTDeEXLx8jJHwmiSRJHkQXHRSSFpYcjyKBJccjhh3aFJwMbwZrAncA2AA4A1EGMgnyC4EOvg+jDsULwwjLBoUGnQirDO4P2A6PCOL/Ufgx8/XvAu4l7RTtZ+2y7Q/tYOrV5VrhaN453HXZFteu1/zbEOIc6B7uxvPG9hz19e9x6gzmNuIX36Le/+Fo56Tr7OyY63XohuO/3BzW99RA4FD7nCFkSKllTHUHeBJwBWFVUQFIFUfqSfVJVEQLOo8sChyMCCPzdd2myRC727WOvLHNA+Ts+E0HOg0uDOgHaQREBPwHbg6hFWAbTh39GAANr/pC5iDUy8U/ulGxYK3qsCq7DcgQ06/Z+Ntl3AXfDOc/9FcDOBHzHGUmRCy8LFgnQB39D1IB9PO46mbmL+X55GDl0uac6D3pk+il6NPrw/Jc/EoH1BIlHl4n+SufKrEkpR10GLkVVRRpE/4S7hIgEo0PfwtKB9MDHAEu/8H+jgBYBBcJ4g0IElkURxOHDk8I5QOfAtICLAJbAJ7+Qf3t+sj2F/LG7gztp+sB6tLogegc6Irm7+Mx4aveK9zb2ZXYWNng3Cjjmeot8HPxse486urlPuLa3/vfiOIO5VPlLeRL5GnmOOg250HjUd572zHfa+7wCvEvkFOPbNR2z3NbaHhaPk/2SJZGDUU3QSM5oCweHXsMb/uK6TfXLcdSvWG84MRT1TDqCP6KC6IQWw+gC50IQgiUC9QRyBdrGQgVBQx6ANfyreIT0RnBvrUvsEaw3bWTwEfO8doV42/m7+cL63vxMPtTB2wUASBRJ9go8yQfHfUSugc4/Nzwm+aZ3/TddOEi5/DrIO+N8ZvzWvUf+AT+SwexEegacCIUKDAqeCfMIRgdGxvoGQoXtRLeDoYMPQueCrsKMgsRCw4K6ghzCNcINwruDJwQhhPCE/wQuAzwCMsGSAZoBqIF4wKF/hX6APeY9W/1D/bh9sb2gfT6777qzub05GPkzOOW4vfgZN9q3tDePeF15R/qoO0U74jutOy56r7pHeoC6yXrBepK6DrnKOjo65zx8fW89JfsAOHN2MXaJesOCjQyclkwdf9/UnuvbJJagEuFRK9F10iMRts87S/pIyEYDgls9dLfW8ytvve5nMAv0hPqBgGvEIAWSBSZDgwKEwmWC/0PPxRXFrwU6A5WBcz4DupM2j3Lbr7ttAKwe7E2ukXIYtes48nrl/DP81r3J/1NBucRPB19JXkpsykFJ2MhHhhMC6/8Ge8J5fHfVeCN5U3tS/RV+Lv5avr9+y3/kQSjDIMWoR90JZ4nHyhzKV4sIy/ULukp2SH5GZIUnxFEEFoQmRFCEkMQ1guVB6EFuQWOBrwHbQklC10MuQ0aEG4S8hFEDRcGNf/K+Yr1mPK88a/yl/PC8jfwE+3f6VDmUuKc3hrcL9vY2yXeIuJH51Ls5e9I8Z3wm+5K7M/qJ+uq7czxLvb++Jb4cPTs7fvnheWp5/Xs3PFL8mDsEeMm3vrlvP0NIa9GSWXPdu15KHJQZu1cvlj1V2hWhFA9RYo23CcgG/MOaQCB7vXaWshduUCyOLhezOfn5v+LDb0RFhEJD4ANVg4zEqIWrBfZE0UNqQZqAOT4Pe6f373NSbtqrMWk56UqryK+uM5K3Gjkmei47G/zyvyMB5kSthw+JAcoXyiLJnQjxB4bFzMLkfuU6x7gOtwC3wvldesw8e31YPn6+27/ZAWdDdgVzBsFH9YgviI7JTEo2CtHMOozbjOLLNUg3BRGDG8H9gQzBBQFfwZ4BjsEMgFQ/zH/KgCqAeEDJAcGCysOGw97DU8KpAY1AiD8+vQ479vsS+077gTubuyW6YPl/OCY3V/c09zN3dPeMeA24trkzedv6gHsR+zC6+vqu+lx6GXo0+rB7vrw4e4t6azjbOLZ5rbucvXW9mbxGOel3G3YsuBW+MYbqEHsXxZxRnXUbzVlOVqpUhZPbkzURgE9+zDOJdocoRTYCej5FuWyzpq7yrA8ssjA7df97oH+7QTGBQcFsAS+BeAICw1FD2INZQj0AiT+wfg88eXmlNnNycO5OK2Ip+upTbPnwALPc9pU4gfoXO1a86D6mANiDbkVMhveHmIiDiVeJDMf1xa0DPwAYfST6XDjaeLX5Dnp2O669KH5MP3n/7IB4QELAeoBSQeBEZAeFCwsOLdAEkNuPZ4wbiD6EeEIWQXaBKcEpAPYATL/tPtd+JD2VvY19lH1//R59039iwRXCqgM4Qp0BXv9jPSX7GPnueXE5pvox+kK6qbpXOjO5X7irN8Q3nPdr91k3xTjEujJ7AXwh/GZ8YXwge7q65Xp0+jD6jDvWfQr+Lr5Nvka9zb0XvLm82v5RgCgA47/7vNl5dnb3N6j8QER3DTnU35n6G1AavxhqllcU0RPg0z+SPhBujZQKrog7hkeEb4BFuxa1Py+kq/QqT2w0cCq1Lnkbe6H85T22/jn+jT9tv+WATUCKQLgAgQFRQe6BswAGfWN5fbU9MUeu7S2+bhev6HGu82i1WLeOOYM7Bfx1/aj/C8BpgXyDKcXfiKgKf8reCpSJXocrxFdCMgCTADW/gv9r/rV96703vE88DTwzfFC9VD73wRVErEiDTNwP/pEgkMPPfkz9ymFIOQYQRNlDgcJRQM7/oL6v/ei9ZL03vT29RX3i/iL+3IArQW8CDcIkQQ9/3v5APRG78fr7enM6dzqF+zR7Hbt+e4u8S7yHvB66/Tm1uQu5bLmmej26rDtK/D78T/zBPTq86fymPCc7rjtBO9T81r6SALACDsMnwzjCogI/wbyBvIHHgnKCQkJCgU1/KvvUuSH4FfoKPsrFA8tVkH+T/RZJ19dXldYVFFLTU5LAUf8PhU38jJqMMkpjRw6C874quVA0i3C5rntuY++ScSWyibSS9pq4QTn6Oub8JT0OPfe+Jv6dv26AbcGrgp0C4sHHf/586voIt/z17zSO8/EzbDOztG61lLdMeUD7TzzqveB+7n/LgT7CIkP7RilI4osHDKcNTQ4hzhaNMkrQSGbFvQL0QHq+of6ogEvDmUc4SeaLOkoWB9ZFTIPZw0EDj8PAxAlD90LCwfDAikAiv7h/D37DPoB+cj3OfeK+Ev7Nf1n/A35rfSS8Hjt/+tn7A3u2O9N8cnyyfRw97T6RP4qATUCDAGh/iz8L/q2+Bf4zPil+qH8t/2D/V/8Fvtk+nD6xPoX++777P2wABgDqgTwBSkHegdCBmkEegPDA3oEkwUpCKoMoRH8FOUVvBTlEWwNeAdfAKf4vfE47gHwEvYj/dICPQcnCyEOpA/zEAsU2BgLHQgfnx9FINcgISDyHVcb/RhhFr8SBA60CHID//7x+x36ifh19g/06/Er8JruVO3I7PjsTO0u7bDsbewJ7ZruavA98U3wGe4G7B3rbeuK7C3uKPAt8hD0/vUH+LL5gfqm+rX6uPpI+qX5/PkM/Bz/ywGqAzsFrwZaB6kGFAXUAyME7gaGDOYTihrqHXwd8hptGMAWfhUBFOcR9g5OC9QH0gXWBSEHZQjZCGQIJgdkBccDDgMwAysD8gFq/0X8K/ly9nb0m/PJ8030hPRp9Dv0BPS887rza/SZ9Xn2n/Z+9sL2YvfC95v3affk9yz5qfqn+wP8O/zb/Ov9Bf/T/zQA5/+L/lv8gPo1+pb7pv1r/50ATQFvAR4B2wATAa4BfALCA9EFNgjlCUgKqwmECOwGBwV2A9EC8gIpAxYD5gK8AmoCugG8AKz/vP4n/hj+Yv6A/gP+9Pyn+136N/lR+Lr3cPeH9y/4U/lF+jr6FPmM94D2OfZz9sb2APcq93D35/dr+Mr4JPne+TD7z/xF/mv/YQA2AcwBEwIhAgYCwQFdAfMAkwBEADAAdADZAPAAnABIAF4AxQAUASIBFgEHAfYAFwG1AbACXAMaA/MBWwCt/gn9tfs0++X7kv1j/1gA4P84/j38vfoA+vn5p/r7+3j9Q/7e/an8ePvN+oT6L/qR+dP4aPi++Mz59/p/+xL78vmv+Mz3l/cG+LL4Nfmp+Zb6IPyL/dj94vyj+0D7DPx7/cr+if+2/5L/d/+Z/+X/HAAcAPz/8P8iAKIAWwERAo0C1wI7A9wDUwT2A6MCKgG1ALIBbAO9BAkFhASrA9ICKALUAc0BrAH3ALT/bf6W/QL9Nfwy+5j67PrX+3P8Qvyo+1P7X/tU+/D6mfrZ+pz7SfyV/N/8gf0Q/qz9L/yj+kf6Qft2/L78Cvws+9H62vrh+vD6ePuT/LH9Pv5k/s3+pf85AOH/9v6t/r3/ngE1AwMEbwTuBD4FuQQ8A4MBfgBxANEAAAH/ADoBzQEsAr4BqgC9/4X/vv/L/6L/5v/4AEECswL7AeAAVQB4ALkAzQD7AGgBggGWAMr+Hv1X/EL8R/xh/Af9Qv5a/7X/rf8mAGABjAKzAs0BsQAVAOn/vv+T/97/0gDrAVsC+gF2AY4BQgLjAuoCgAI4AmMC0gIsA1oDdwOBA0EDlQKzAQABrACdAL4ANAEKAtkCEQO/ArcCqwMtBfkFTAW7A3QC5gFrAVUA7/47/tD+KAAnASIBXwCo/3v/qP+Y//7+P/4g/v7+XwBlAaQBcwFjAZgByAGzAWIBBAHbAFYB0QLmBEcGyQXBA/gB7gFCAysEcAOoAXUAvADtAdsC6AJXArkBagGDAfYBeQKdAjkCzwElAnAD/wTrBfAFewUCBZ0EQAQFBPID0ANuAwIDAQNyA78DRQMCApIAsP/E/84AZgK4A+0D3QJwAQIBKAL+A+YEGgRvAoMBHQJ/A0UEwANmAi8BywBbAYQCkgOvA3UCXQCN/v/9wv4EANgA8AC3AMIANAGoAbgBdAFJAX0B9AFrAt8CgANGBMUEgwR/A1oC2AFCAjwDLQSvBJsE4gOfAlIBuAAiAQkCeAL8ARMBnAALARYCFANvA+4CxAF7AK7/qv89APEAZgGXAcABDAJpApICWALVAVIBBAHrAOIAygCiAIsArwANAWsBgwFTASYBQAGFAZUBQAG4AFgAVAC2AIMBpAKyAwgEWAMkAnsB9AHyAiEDzgG8/3f+3v5oAOMBmwKYAgoCAwHf/3T/SwC4ATwCGQFK/4L+WP+/AGIBGwHHAOIA6AAsANr+wf1Z/Vz9bf2w/XL+g/9LAI4AqwARAaAB5wHWAdEBFQJKAvoBOwGmAKwAGgFaAQQBLQBE/7X+pf7K/qn+GP6G/Zb9Z/5a/7b/ZP/s/rn+sv6K/lL+eP4//28AkAE9AkMClgFrAE3/y/7//mf/Yf/L/gr+n/3F/Wz+S//w/+T/Ef/8/Xr98v39/sz/3f9d/9X+q/7t/lz/p/+K/wH/Zv5C/uX+AADFAIQAUv8E/nn9xP00/ib+xP3J/Zf+s/9OACcAov8Z/3/+xv1W/b/91v6l/2P/YP6Z/YP9jv0G/Qz8b/uq+2j8Ff2P/Qn+eP55/u39S/00/cT9hf4F/0j/kf/q/xAAx/8j/33+Jv4m/jT++v1p/dX8sfwT/Zf9vf1v/f78uPyf/JL8kfy3/PL8Ef0K/SP9nP1S/tL+1f59/h7+5/3P/cD9r/2U/XX9bv2R/bH9dP3I/CL8FPyj/D39Y/02/UH9y/2j/nr/LgCjAJAA2P/m/mP+Zv5A/ln9Efx4+xr8Vv0J/rf92/w9/Eb87vzq/b3+zf7h/Zb8D/zs/JP+qf9A/5f9w/vQ+h37Uvyn/Wb+Tf6w/Sr9FP1M/W/9RP3m/Kf81Px2/TT+f/4S/lT9Ef2m/ZX+Af+b/uP9ef1v/Wz9V/2J/VT+h/+QAP0AowB9/6/90vvR+lD7E/0h/3oArQDX/3r+Wv0l/fD9+P5B/43+l/0+/aT9Qf60/gn/TP8p/2r+j/1p/Q3+iP4D/u38pvzY/Zn/YACy/3H+r/2A/UP9vvyH/Ef94f6NAJoB0gFBAfH/I/6g/FT8ff1I/30AjwD6/5z/3f9yANwAzwA8ACj/yf3C/Nn8Nf7w/6oAxf/9/dH8MP3R/qoA5QFAAuEB+QDQ/9r+j/4H/+f/qgAWAToBOwEUAasA9f8O/zr+zP0B/tT+5/+6ABEBCAHNAEUAOP/a/QP9j/1s/3UBYgLqAeMAPAASANf/QP/F/vj+sf8SAJX/tv55/j//SgCQANL/w/45/mj+9f6S/y0ArADGAGcACwBJAAcBVAFwAOH+M/5l/64BIAOJApEA3/5e/qj+7/4R/2v/9f8cALD/Zv8QAFgB2QHFAAf/WP5Q/8cAWwEDAd0AlAGYAvMCfgLQAVQB4wBWAAYAWgAiAbcBuQFkAQ8BvAA6AJD/7/5m/u39uf0d/vP+fP8u/4H+av4K/1D/VP61/Bb8OP0Z/zgAUwBaAOwAaAHdAF7/8P1L/TD9I/1B/fz9Ov86AIgAlAAHAbgBtwGKAAP/g/6P/0QBUgI/AqYBWgGLAb0BYwFlACL/Nv47/nr/kgFsA8IDJAKG/6P9pv05//sA2gHYAZcBXAHXANz/7P7G/nT/MABNAPb/2v8wAHcALACD/xj/F/8P/7X+d/4N/3kA4gFZArQBdgAn/wn+Wv1//aH+RAB+Aa4B6wDP/+r+hP6R/sn+y/5y/hf+Tv4x/w0ABgAY/0z+wf5uACMCowLIAXcAq/+6/2UAUQEqApICJwLmAGP/d/6X/nX/SgCKAEAA1P+J/1D/Df/x/mP/gwDVAYACCwLCAHf/2/4b/+n/wAAZAawAwP8v/73/IwEKAjoBAP8b/Rf9zv6rAFcBxwDI/+L+D/5c/TD9vP1y/oH+5f2V/W/+IgBwAXIBbQBP/6r+c/6I/gj/DwBHAQoC+AFDAWcAvf9f/1X/pv80ALUA6wDmAPwAYgHmARoCxQETAUYAZf9v/tL9Tv4ZAD4CMQNXArEA1/9WAFoB5gH3ASkCegISAoEAsP4N/uD++P8xANf/8f+cALcAcv+U/aT8Hf0T/qL++v6k/0gAAgDq/mT+e/83AYEBp/9r/ST9CP/1AO0AMP+f/XL9EP5H/vT9+f3Z/uH/9f/p/sT9qv24/uv/HAAM/5T98fzH/an/hAFkAvEBegDO/u/9lP6EAIQCMQMzAosAjv+r/0wA0gBFAeYBYwL3AYUAFP/Q/qr/ZgAkAGj/V/8vABYBWQFUAbEBJAKZAcD/4v25/YH/lQEdAuUAf/+f/3oBogNWBAUDvQA0/07/YQDyADAAwv4B/pL+1//HAO4AcQB8/yH+4/yj/Ln9OP/E/x7/d/73/kkABAFrADr/lP6b/n7+wP3v/N38if0z/nH+uf62/0EBXwJBAiAB//+Q/5f/Tf9q/q39OP5IAK4CtgPGAuUAq/+2/3MAKgHLAYIC/wKgAl8BFQCf////lgDzAAQBrACy/1T+if0Y/pn/xgDWAC8Ak/8J/yj+H/3R/Kr94P5Y/w7///6v/1gA7v+Z/qr9Hv6h/yEB7AH3AWUBUQAd/37+Av+NAHAC2gMhBPgCvACX/s/9w/6YAB8CyAKjArwBHQB6/ij+wP8GAtwCgwGA/9n+1//rAMQAzP9k/xgAIQF/ARYBfAAlAAgA/P/y/+j/x/+P/2v/c/9+/1P//f6//r/+7v5H/8n/HgCg/xj+hfxx/Fz+AQGgAqwC9wFAAVgA+P7u/Zv+MAH2A78E/AIXAO39Pv2w/cX+SwDxAeMCVQJ8ALT+cv7y/98BfwI5AR//6P1n/uv/KAGPAYoBhgEvAfr/Qv5R/QT+wf8nAYMBLwGVAHf/sv1V/BT9UgAXBG0FFwPU/t77Mvwe/zgCggO5AgEBp/9E/67/TAB7AOT/1/5O/jP/XwFKAwcDHQBf/Kj6XPwMANEC7gIFAcn+FP3S+0z7hPzR/4wDEQVGA8r/Wf07/Yz+0v+wALwBCAOTA3YCQACe/pT+iv84AFAAoADCAQkDMQPkATAAaf+5/xwAqf+3/o/+2v+5AZACtgEbAB//Jf+x/4UABAIgBIYFmQRcAeL9hPzH/SQAxwETAoMBjQA3/7b91/w3/Un+uP77/RP9YP3p/k8AdACr/xb/MP9h//X+Ff6p/WH+9P9LAXEBgQCg/9r/+ACtAfsAZP9l/uf+VQBbAUUBkAAjAFAAtQDgAMsAnwBdAAQA9/+oAOYBswJPAh0BMgAIABwA2f9x/47/XABJAaYBPAFWAHP/A/80/77/IAAqACYAbgDZAOIATwCR/0//s/8+AGcALAD4////CQDq/+z/ZAD/AOIAyP+R/mr+e//GAEQBtwCE/zb+ZP2n/Rr/8gD6AZ8BZABM//3+c/8+AN4A9wB5AK3/FP8a/7//hwDTAGAAk/8c/2X/TABbAQQC2AHDAFX/j/4d/6gAHgKaAgAC2QDK/zT/E/8Y//7+zv7J/gf/Wv+K/43/Zv8B/2r+BP5G/jb/RgDOAI0Axf/2/pj+1v5y/+X/z/9H/8P+r/4Q/43/xf+e/1L/OP93//v/mwAkAU8B9gBjADMAvQCgARwCzAH1ABsAnf+o/0cANQHaAb8BCQFUABkARgB1AFYA9P+c/6L/EgCpAAMB8wCaADgA/f/z/wwAJwAlAA8AEQBFAI8AvAC0AIsAbQCIAN4AJQH1AFQA4f80ACIBzQGmAQABfwA3AMD/Bf+h/hH/3//v/8j+Rv3K/Lv9DP9W/0/++/x6/OP8aP1c/cz8NvwA/ED80Pxa/Wr9wfyq++X6Evso/HD9Df6e/YL8ivtO+8b7gfwi/Zb96v0Q/v392/0F/rn+2/8PARAC1AKCAy4EyQRIBcsFkAaxBxQJhwrQC6IMuww5DLgL6QvmDBAOlg4bDucMmAuxCkcK9Ak0CdcHIgZoBLwCCgFZ/7z9KPx++sz4TfcM9tf0l/OE8uPxq/Ga8XXxD/FJ8EPvie6h7mjvLfCA8KHw4PAL8crwdPDt8JXyo/Tj9fj1pfXe9dP29PfJ+Iz5yPp7/Nr9Hv52/e78Yf23/i4AKwGTAZ8BpQH4Aa8CgwMlBKsEaQU9BngGtgWjBIAE1QXiB1gJbQlDCIgG6gS+A/MCXQIeArcCbwSiBt4HCgeiBKwCKANHBjkK2AyBDS4N7AzCDDMMagtJC0oMuw1ODj8NygqwB5AEugFr/9r98/z++/P5ZfYJ8iHuYeuJ6Rbo3+bd5bXk6+J84PndINyC22zcrt5k4WjjQuR+5APlROZF6PbqSe7v8WT1OfhO+tP7Pv0V/44BhQTMB1MLmQ6GEIQQsw8lEKISyBW5FxgYvxcrFxoWoBR6Ex0TBRN/En4RRRCrDlcMkglDBwEGewXaBH4DVgHJ/mz8tPq5+Un5/PhJ+M72z/Q+89TyNvNa88Ty7vF08WTxj/Hq8UDy+/Hw8BLwl/Bj8ubz3vO78vzxkPIt9Pj1T/cB+C74GPgP+Fz4OPmT+vT70Pwm/ZL9i/7V/90AhwEbAqoC9QL2AisDGQTTBfsH9AkGC8kKzQl6CdgKeA3jDxMROREbESMRJxHvEJ4QkxD3EGwRZBG0EK8Plg4yDVULdgk8CIEHWQYyBG4BpP7h+wv5i/bX9KTzNPJY8I7uA+066/Xo5+YA5lzmUOc46NfoK+lm6fHpIuvf7M/u2/Af82/1Ufeb+Lb5J/sQ/Un/lwGrAysFCQalBmgHagifCRULuAwTDrMOuA6uDvEObg8GELUQWhG0EagRSRGDECoPmA2lDLQMAg1lDJ0KagiHBgUFvAO9AhMCbwFwACL/1v2//N77Rfsd+1L7h/t2+zL7+/rt+vX6CftI+9H7hfwA/fX8j/xP/Ir8Hv2v/Qr+KP76/Yj9Kf1L/fL9qP4L/y3/Rf9U/0H/Jv89/4X/z/8RAHUA+gBiAXgBVAEwAS0BSAFxAY0BgwFmAXsB8QG6AqQDkARXBbwFtgW5BV4GvQdXCaYKhgsGDCUM6QutC+gLuwzDDXkOkw4lDnsN3AxHDH0LYAozCV0I4wdUB0kG1wRdAxIC4QCp/2/+TP1H/Fv7ifrU+TL5kPjf9x73T/aP9Qz17fQw9aD16/XO9Wn1N/Wk9aD2ufeS+Dj5+vkC+zH8Uf1Q/kb/VgCFAbsCwwOBBB4F7QU0B9oIdQqZCzgMoww3DfwNrA4cD3EP3g8vEAEQSA90DucNlQ0uDYUMpgurCpsJhQiPB7kG0wWnBFoDRAKHAfUASQB2/5b+uv3V/PX7SPvx+uX68frq+r76gPo2+uf5mvlk+Vb5cvm4+Q/6Uvpw+ob6y/pR+/j7nfws/ZL9yP3m/Qn+O/6D/vf+qv9XAJwAawApACIATwCWAPoAkwE0AoQCYwIdAg4CSgK2Ak8DCgSeBNoE0gTcBDYF6QXfBuUHqwjjCLMItAheCWoKGQseC80KdAoBClEJsgiRCMIItwgfCCoHGAb7BNsD0wLtAQ8BFwAA/+X9w/yL+z/66vii93P2fvXO9Cr0TfNY8pvxJPGy8DrwHvCO8BnxMfEC8UrxOfIl86rzOfRr9RL3gPiB+Xz60ftN/Z7+x//wAB8CPQNVBHUFXgboBkIHtgduCDgJ+AmWCgkLPAshC/gK5goECzcLXAtFC9wKTArMCXgJCAkXCLgGgwXJBCMEBQOMASsAAP/Z/cb8/ftV+5z6yfkb+ZD4/PdS97T2XPYn9v71zPWc9Yb1l/XM9d71wPWp9dH1KvZz9pL2uvb99i/3JfcK9y/3hvfj90X4xfg4+Wn5gPnT+XT6Fftm+5H7/vvE/Kz9c/7+/jD/IP83/8//0ADoAeQCsQMvBCME8QNhBK8FJAfYB+wHFwiHCMIIuAjpCJUJRApyCjgK8QmyCUcJtQg7CMgHCAfwBcgEzgPRAoIB5P85/qj8D/t/+R747Par9V70T/Nk8lvxO/Bj7+3ufu7A7evsgeyd7OzsPe3d7c7uk+/t70zwNfGY8g30WPWY9u73TPmh+u/7Pf2K/r//1ADTAcYCnQNMBOIEeAUXBqIGNAfYB18Iegg+CB0IMAg9CBwI/AfvB8YHOAdwBu8F7QUOBs4FEgXyA70CqgHpAGcA6v9N/4T+tv3v/Dj8p/tm+1T7IvvO+p76jfpT+gL62/nu+ef5ovlg+X355Pky+jD6BPrx+en5+Pke+mX6rfq/+qD6h/qt+gb7Z/ut+937+/sW/C78P/xm/OX8wf2G/vL+Lv+B/+D/KABiAJ4A2AD6AP4AIgGsAXgCMQOBA4EDcAOJA/IDnARoBQYGOgbtBWUFGAVdBSAG1wb3Bn4G2AUtBXEEsAMmA9QCawKbAWQAR/+U/gH+GP3n+8z6+PlL+aP4D/iw93H3+fYq9lf1CfVB9Z/16vUq9m32uvYp98D3gfhj+XD6qPv//En+YP9oAKcBFgNkBFwFBgbIBt8HKglBCuoKaQsEDLoMJg0jDdcMdwwVDJsLEQt5CuoJagn3CGAIlQe2BtYFKQXeBKAEyQOTApIB2ABJAAAA1/9l/7L+3/0I/Un8kfsD+9X6wfpy+uH5VPkF+QH5EvkT+Tj5Z/mJ+bn5Jfqy+gX77vqx+sP6Ivue+x/8x/yM/UL+of6z/tX+Of/r/7wAbwHQAekB9QFMAu0ClwMtBKEE3QQPBXcFIQYVB+oHMQggCDsIdQi4CO4I6wgjCcMJIwo3Cs0KjQvlC94LkwtAC2sLNwwnDfUNJw6aDakMEQwEDAkMpgsGC4cKzAmNCOQGnAXKBOYDbgKeACX/7P2i/BP7rfl3+Db3vfVy9Jbz3PIS8k/x+vDn8Jjwnu+p7pbuoO8H8d7xEfIh8uTyYfQY9nX3yvhV+uf7bf0R/9EAgAJJBNcFOgeRCPUJaAsbDdcOARB+ELkQlhGwEusS2RHCEMIQkRENEooRuBBIEGcQZhDWD6IOeQ3dDNMM9QykDMALWgoPCRoIjgcHB14GgAVrBEkDBQLNALz/Jv+o/tL9kfxj+7L6OvqR+YL4ife29r/1Z/Rq81PzufPT82rz/fKt8pHyZfJX8oryAfNr837zYPNT88rzuvTX9Z72Gvd39+X3Zfga+U36vfsa/S/+T/+dABQCVQNtBJQFswa+B7sI2gnVCqMLeQzpDdQPfhFfEpgS3BJiE04UgBXPFoMXWRfYFpYWfBYVFqcVeBVgFWkUehJhEN8OpA3nC5oJGQe5BD0C1v+p/a77g/kM93n0+fG6757twOv76WPoCOcl5k7l7ONU4obh8+GS4rLipuJb483kYua65xbp0OqY7FPuH/Ax8j70RfZt+Lv6pfz9/W7/XQGeA3UFGQfuCO8KeQxtDTcO+A6QD+8PihAbESQRiRBgEFoRqxIRE2oS8BEhEpYSlxJ6EpYS0xKeEq8RVhADDycOcg3BDO0LHAv5CTwI9AWpAwYCygAp/0X8evhH9KjwFO9Q8bP2Jfud+i315u8L7yXyVvQ48pbs6uZz4+jhYuH94Kjg0d+r3sndZN5Y4M/hIeHC3uPdROAT5Vzp4OvJ7PnsDO3s7TPxq/Y9/LX+6v0B/DX88f/qBqAPYxeWG1Ub3xm9GpUf+CXjKtksOy3zLSwvjTABMb8w7y6MK/QmkSPJIhkj3CCSGc8PIgcUAtT+G/zd+Kj1IPLK7cHpZOY05Obg+NxO2eDYMttI3uLfA9983YTbiNvC3JHgMuTd5v3mz+WD5XXl5eYU5hHnwOVV6IHohew=\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 0.480s\n",
      "Language: French - Quebecois\n",
      "subset: CallFriend\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import Audio\n",
    "import IPython.display as ipd\n",
    "\n",
    "id = 42\n",
    "example = talkbank[\"test\"][id]\n",
    "\n",
    "audio_array = example[\"audio\"][\"array\"]\n",
    "sampling_rate = example[\"audio\"][\"sampling_rate\"]\n",
    "\n",
    "ipd.display(ipd.Audio(audio_array, rate=sampling_rate))\n",
    "\n",
    "print(f\"Duration: {format_seconds(audio_array.shape[0]/sampling_rate)}\")\n",
    "print(f\"Language: {example['full_language']}\")\n",
    "print(f\"subset: {example['subset']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c8b6611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "durations = {}\n",
    "for split in [\"train\",\"test\"]:\n",
    "    durations[split] = [\n",
    "        ex[\"audio\"][\"array\"].shape[0] / ex[\"audio\"][\"sampling_rate\"]\n",
    "        for ex in talkbank[split]\n",
    "    ]\n",
    "\n",
    "# two-panel histogram\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4), sharey=True)\n",
    "for ax, split in zip(axes, [\"train\",\"test\"]):\n",
    "    ax.hist(durations[split], bins=30)\n",
    "    ax.set_title(f\"{split.capitalize()} split\")\n",
    "    ax.set_xlabel(\"Duration (seconds)\")\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59df4401",
   "metadata": {},
   "source": [
    "## 5. Preprocessing\n",
    "\n",
    "Before we can fine-tune Whisper, we need to transform our raw dataset into exactly the inputs the model expects:  \n",
    "1.  `input_features`: 80-dim log-Mel spectrogram frames.  \n",
    "2.  `labels`: target tokenized transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df4e4b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just clean up unneeded columns, keeping the audio and transcript\n",
    "talkbank = talkbank.remove_columns([\n",
    "    \"language_code\", \"subset\", \"full_language\",\n",
    "    \"switch_id\", \"transcript_filename\", \"orig_file_start\",\n",
    "    \"orig_file_end\", \"channel\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34d342ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperFeatureExtractor, WhisperTokenizer, WhisperProcessor\n",
    "\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(model_name_or_path)\n",
    "tokenizer = WhisperTokenizer.from_pretrained(model_name_or_path, language=language, task=task)\n",
    "processor = WhisperProcessor.from_pretrained(model_name_or_path, language=language, task=task)\n",
    "\n",
    "def prepare_dataset(batch):\n",
    "    audio = batch[\"audio\"]\n",
    "\n",
    "    # compute log-Mel input features from input audio array\n",
    "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "\n",
    "    # encode target text to label ids\n",
    "    batch[\"labels\"] = tokenizer(batch[\"transcript\"]).input_ids\n",
    "    return batch\n",
    "\n",
    "talkbank = talkbank.map(prepare_dataset, remove_columns=talkbank.column_names[\"train\"], num_proc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ac63321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_features', 'labels'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "talkbank['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2c3f23",
   "metadata": {},
   "source": [
    "## 6. Data collator\n",
    "\n",
    "Because audio and text lengths vary, we need a custom collator that pads inputs and labels separately and masks padding tokens in the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e3ea2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
    "        # first treat the audio inputs by simply returning torch tensors\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # get the tokenized label sequences\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # pad the labels to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        # if bos token is appended in previous tokenization step,\n",
    "        # cut bos token here as it's append later anyways\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n",
    "\n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0e8f88",
   "metadata": {},
   "source": [
    "## 7. Load the Pre-Trained Model and Tokenizer\n",
    "In this step we load the pre-trained Whisper model with 8-bit precision to save memory, and inspect its architecture.\\\n",
    "Then we disable forced tokens so generation follows our prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b430c945",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "================================================================================\n",
       "Layer (type:depth-idx)                                  Param #\n",
       "================================================================================\n",
       "WhisperForConditionalGeneration                         --\n",
       "├─WhisperModel: 1-1                                     --\n",
       "│    └─WhisperEncoder: 2-1                              --\n",
       "│    │    └─Conv1d: 3-1                                 185,088\n",
       "│    │    └─Conv1d: 3-2                                 1,770,240\n",
       "│    │    └─Embedding: 3-3                              (1,152,000)\n",
       "│    │    └─ModuleList: 3-4                             85,045,248\n",
       "│    │    └─LayerNorm: 3-5                              1,536\n",
       "│    └─WhisperDecoder: 2-2                              --\n",
       "│    │    └─Embedding: 3-6                              39,832,320\n",
       "│    │    └─WhisperPositionalEmbedding: 3-7             344,064\n",
       "│    │    └─ModuleList: 3-8                             113,402,880\n",
       "│    │    └─LayerNorm: 3-9                              1,536\n",
       "├─Linear: 1-2                                           39,832,320\n",
       "================================================================================\n",
       "Total params: 281,567,232\n",
       "Trainable params: 82,059,264\n",
       "Non-trainable params: 199,507,968\n",
       "================================================================================"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(model_name_or_path, load_in_8bit=True, device_map=\"auto\")\n",
    "\n",
    "from torchinfo import summary\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1333b3e",
   "metadata": {},
   "source": [
    "The model has arguments that we will override such as:\n",
    "\n",
    "forced_decoder_ids (`List[List[int]]`, *optional*):\n",
    "            A list of pairs of integers which indicates a mapping from generation indices to token indices that will be\n",
    "            forced before sampling. For example, `[[1, 123]]` means the second generated token will always be a token\n",
    "            of index 123.\n",
    "\n",
    "suppress_tokens (`List[int]`, *optional*):\n",
    "            A list of tokens that will be suppressed at generation. The `SupressTokens` logit processor will set their\n",
    "            log probs to `-inf` so that they are not sampled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8361a72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model forced_decoder_ids: [[1, 50259], [2, 50359], [3, 50363]]\n",
      "model suppress_tokens: [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362]\n"
     ]
    }
   ],
   "source": [
    "print(f\"model forced_decoder_ids: {model.config.forced_decoder_ids}\")\n",
    "print(f\"model suppress_tokens: {model.config.suppress_tokens}\")\n",
    "\n",
    "model.config.forced_decoder_ids = None\n",
    "model.config.suppress_tokens = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9134b5",
   "metadata": {},
   "source": [
    "## 8. LoRA Fine-Tuning ⚙️\n",
    "\n",
    "We will now integrate **LoRA adapters** into our pre-trained Whisper model via the PEFT library. \n",
    "\n",
    "LoRA (“Low-Rank Adaptation”) freezes the original weights and learns only a small, **additive** low-rank update in selected layers. This reduces the number of trainable parameters and accelerates fine-tuning. \n",
    "\n",
    "Moreover, because the LoRA updates are stored separately, you can easily swap in different adapter checkpoints— for example, to support new languages or specialized domains—while keeping the same underlying base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1929ee48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters after applying LoRA:\n",
      "trainable params: 884,736 || all params: 242,619,648 || trainable%: 0.3647\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# Configure LoRA settings for sequence-to-sequence language modeling\n",
    "lora_config = LoraConfig(\n",
    "    r=8,                           # Rank of the low-rank matrices\n",
    "    lora_alpha=32,                  # Scaling factor for LoRA updates\n",
    "    lora_dropout=0.1,               # Dropout probability for LoRA layers\n",
    "    target_modules=[\"q_proj\", \"v_proj\"]  # Target modules in the Transformer to adapt (adjust as needed)\n",
    ")\n",
    "\n",
    "#Some models freeze embeddings by default; this ensures LoRA can adapt them if needed.\n",
    "model.enable_input_require_grads()\n",
    "\n",
    "# Wrap the model with LoRA adapters; this makes only the LoRA parameters trainable.\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# Optionally, print trainable parameters to verify that only the LoRA layers are being updated.\n",
    "print(\"Trainable parameters after applying LoRA:\")\n",
    "model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11597955",
   "metadata": {},
   "source": [
    "## 9. Define the Evaluation Metric (WER)\n",
    "\n",
    "We use the Word Error Rate (WER) to evaluate the performance of our speech recognition system.\n",
    "The `compute_metrics` function decodes model predictions and ground-truth labels, computes the WER,\n",
    "and returns it as a percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a977bdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "# Load the WER metric from the evaluate library\n",
    "metric = evaluate.load(\"wer\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    \"\"\"\n",
    "    Compute Word Error Rate (WER) for model predictions.\n",
    "    \n",
    "    Args:\n",
    "        pred: The prediction output from the trainer containing predictions and label_ids.\n",
    "    \n",
    "    Returns:\n",
    "        A dictionary containing the WER score.\n",
    "    \"\"\"\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    # replace -100 with the pad_token_id\n",
    "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e193d26",
   "metadata": {},
   "source": [
    "## 10. Setup Training Arguments\n",
    "\n",
    "We use Hugging Face's Seq2SeqTrainingArguments to define our training configuration.\n",
    "These settings include batch size, learning rate, number of steps, evaluation strategy, and logging.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b344e627",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/canary/lib/python3.10/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"results\",\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=1,\n",
    "    learning_rate=1e-3,\n",
    "    warmup_steps=50,\n",
    "    num_train_epochs=3,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    fp16=True,\n",
    "    per_device_eval_batch_size=8,\n",
    "    generation_max_length=128,\n",
    "    logging_steps=25,\n",
    "    remove_unused_columns=False,  #required for the PeftModel forward\n",
    "    label_names=[\"labels\"],  #same reason as above\n",
    "    report_to=[\"none\"],  # Disable logging to avoid cluttering the output\n",
    "    )   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ec12b1",
   "metadata": {},
   "source": [
    "## 11. Initialize the Trainer\n",
    "\n",
    "We instantiate Hugging Face's Seq2SeqTrainer with our model, training arguments, datasets and\n",
    "data collator. \n",
    "\n",
    "We are just using the first 100 segments for demonstration, if you want production-quality transcription, you should continue fine-tuning with a larger dataset and more training time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58940bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45417/2961733102.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=talkbank[\"train\"].select(range(100)),\n",
    "    eval_dataset=talkbank[\"test\"].select(range(100)),\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fabf7b8",
   "metadata": {},
   "source": [
    "## 12. Fine-Tune the Model\n",
    "\n",
    "We now start the training process. The trainer will fine-tune the model using the LoRA adapters,\n",
    "updating only the LoRA-specific parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc52d4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 01:20, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.890726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.955700</td>\n",
       "      <td>2.560604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.955700</td>\n",
       "      <td>1.943963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/canary/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=39, training_loss=3.2936521676870494, metrics={'train_runtime': 82.7204, 'train_samples_per_second': 3.627, 'train_steps_per_second': 0.471, 'total_flos': 8.6957826048e+16, 'train_loss': 3.2936521676870494, 'epoch': 3.0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ab8d0e",
   "metadata": {},
   "source": [
    "**(Optional)** Push the model on the Hugging Face Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5949b87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87f11d6044074dae8551cbf729a15bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "993cc6e9c032405cb23950df542fb860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/3.56M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabolocom/openai-whisper-small-LoRA\n"
     ]
    }
   ],
   "source": [
    "model_name_or_path = \"openai/whisper-small\"\n",
    "peft_model_id = \"diabolocom/\" + f\"{model_name_or_path}-LoRA\".replace(\"/\", \"-\")\n",
    "model.push_to_hub(peft_model_id)\n",
    "print(peft_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5b2d33",
   "metadata": {},
   "source": [
    "## 13. Evaluation\n",
    "\n",
    "In this section we load our PEFT‐LoRA-fine-tuned Whisper model, run it on the test split, and compute the Word Error Rate (WER) metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c964315f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c6d40fb152f4c19a71ecdf5dbdba926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/896 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d14df0595ff04179999f3f2178a17c26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/3.56M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import WhisperForConditionalGeneration, Seq2SeqTrainer\n",
    "\n",
    "peft_model_id = \"diabolocom/openai-whisper-small-LoRA\"\n",
    "peft_config = PeftConfig.from_pretrained(peft_model_id)\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\n",
    "    peft_config.base_model_name_or_path, load_in_8bit=True, device_map=\"auto\"\n",
    ")\n",
    "model = PeftModel.from_pretrained(model, peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d76357",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "eval_dataloader = DataLoader(talkbank[\"test\"], batch_size=8, collate_fn=data_collator)\n",
    "\n",
    "model.eval()\n",
    "for step, batch in enumerate(tqdm(eval_dataloader)):\n",
    "    with torch.cuda.amp.autocast():\n",
    "        with torch.no_grad():\n",
    "            generated_tokens = (\n",
    "                model.generate(\n",
    "                    input_features=batch[\"input_features\"].to(\"cuda\"),\n",
    "                    decoder_input_ids=batch[\"labels\"][:, :4].to(\"cuda\"),\n",
    "                    max_new_tokens=255,\n",
    "                )\n",
    "                .cpu()\n",
    "                .numpy()\n",
    "            )\n",
    "            labels = batch[\"labels\"].cpu().numpy()\n",
    "            labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "            decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "            decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "            metric.add_batch(\n",
    "                predictions=decoded_preds,\n",
    "                references=decoded_labels,\n",
    "            )\n",
    "    del generated_tokens, labels, batch\n",
    "    gc.collect()\n",
    "wer = 100 * metric.compute()\n",
    "print(f\"{wer=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a094ab29",
   "metadata": {},
   "source": [
    "## 14. Demonstration with Gradio\n",
    "\n",
    "Here we build a simple web interface so users can speak into their microphone and see live transcription from our PEFT-LoRA Whisper model.\n",
    "\n",
    "This French‐language Whisper-small model includes LoRA adapters to illustrate the fine-tuning process. \n",
    "\n",
    "It isn’t fully trained, if you want production-quality transcription, you should continue fine-tuning with a larger dataset and more training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03106dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://9cd5f0c486285ae32d.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://9cd5f0c486285ae32d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import gradio as gr\n",
    "from transformers import (\n",
    "    AutomaticSpeechRecognitionPipeline,\n",
    "    WhisperForConditionalGeneration,\n",
    "    WhisperTokenizer,\n",
    "    WhisperProcessor,\n",
    ")\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "\n",
    "peft_model_id = \"diabolocom/openai-whisper-small-LoRA\"\n",
    "language = \"French\"\n",
    "task = \"transcribe\"\n",
    "peft_config = PeftConfig.from_pretrained(peft_model_id)\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\n",
    "    peft_config.base_model_name_or_path, load_in_8bit=True, device_map=\"auto\"\n",
    ")\n",
    "\n",
    "model = PeftModel.from_pretrained(model, peft_model_id)\n",
    "tokenizer = WhisperTokenizer.from_pretrained(peft_config.base_model_name_or_path, language=language, task=task)\n",
    "processor = WhisperProcessor.from_pretrained(peft_config.base_model_name_or_path, language=language, task=task)\n",
    "feature_extractor = processor.feature_extractor\n",
    "forced_decoder_ids = processor.get_decoder_prompt_ids(language=language, task=task)\n",
    "pipe = AutomaticSpeechRecognitionPipeline(model=model, tokenizer=tokenizer, feature_extractor=feature_extractor)\n",
    "\n",
    "\n",
    "def transcribe(audio):\n",
    "    with torch.cuda.amp.autocast():\n",
    "        text = pipe(audio, generate_kwargs={\"forced_decoder_ids\": forced_decoder_ids}, max_new_tokens=255)[\"text\"]\n",
    "    return text\n",
    "\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=transcribe,\n",
    "    inputs=gr.Audio(sources=[\"microphone\"], type=\"filepath\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"PEFT LoRA\",\n",
    "    description=\"Tutorial demo only: this French‐language Whisper-small model includes LoRA adapters to illustrate the fine-tuning process. It isn’t fully trained—if you want production-quality transcription, you should continue fine-tuning with a larger dataset and more training time.\",\n",
    ")\n",
    "\n",
    "iface.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74202f96",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] G. Maheshwari, D. Ivanov, T. Johannet, and K. E. Haddad, “ASR Benchmarking: Need for a More Representative Conversational Dataset,” Sep. 18, 2024, arXiv: arXiv:2409.12042. doi: 10.48550/arXiv.2409.12042.\n",
    "\n",
    "[2] E. J. Hu et al., “LoRA: Low-Rank Adaptation of Large Language Models,” Oct. 16, 2021, arXiv: arXiv:2106.09685. doi: 10.48550/arXiv.2106.09685.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957b4b79",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diarize",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
